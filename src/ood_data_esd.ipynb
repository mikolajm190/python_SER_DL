{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182e1955",
   "metadata": {},
   "source": [
    "# Models load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9aa084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 08:20:37.254517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-22 08:20:39.377205: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-22 08:20:39.385800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-22 08:20:39.456759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:39.457814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 3GB computeCapability: 6.1\n",
      "coreClock: 1.7085GHz coreCount: 9 deviceMemorySize: 2.95GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-04-22 08:20:39.457872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-22 08:20:39.507688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-22 08:20:39.507818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-22 08:20:39.531726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-22 08:20:39.538482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-22 08:20:39.582803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-22 08:20:39.590001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-22 08:20:39.681120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-22 08:20:39.681429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:39.681889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:39.682140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-22 08:20:39.682911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-22 08:20:39.683570: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-22 08:20:39.683831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:39.684131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 3GB computeCapability: 6.1\n",
      "coreClock: 1.7085GHz coreCount: 9 deviceMemorySize: 2.95GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-04-22 08:20:39.684191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-22 08:20:39.684241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-22 08:20:39.684283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-22 08:20:39.684323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-22 08:20:39.684362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-22 08:20:39.684406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-22 08:20:39.684447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-22 08:20:39.684487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-22 08:20:39.684650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:39.685034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:39.685275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-22 08:20:39.685923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-22 08:20:40.964185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-22 08:20:40.964214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-22 08:20:40.964223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-22 08:20:40.964997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:40.965232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:40.965426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 08:20:40.965568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1802 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "path_to_models = '../models'\n",
    "\n",
    "def load_models(path):\n",
    "    trained_models = []\n",
    "    for root, _, _ in os.walk(path):\n",
    "        if os.path.basename(root) == 'model_1_CNN':\n",
    "            trained_models.append(keras.models.load_model(root))\n",
    "            \n",
    "    return trained_models\n",
    "\n",
    "trained_models = load_models(path_to_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2740a",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d773fc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/esd/0015/Happy/evaluation/0015_000717.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/esd/0015/Happy/evaluation/0015_000706.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/esd/0015/Happy/evaluation/0015_000704.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/esd/0015/Happy/evaluation/0015_000715.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/esd/0015/Happy/evaluation/0015_000702.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>../data/esd/0012/Neutral/train/0012_000300.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>../data/esd/0012/Neutral/train/0012_000090.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>../data/esd/0012/Neutral/train/0012_000296.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>../data/esd/0012/Neutral/train/0012_000054.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>../data/esd/0012/Neutral/train/0012_000323.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  emotion\n",
       "0      ../data/esd/0015/Happy/evaluation/0015_000717.wav    Happy\n",
       "1      ../data/esd/0015/Happy/evaluation/0015_000706.wav    Happy\n",
       "2      ../data/esd/0015/Happy/evaluation/0015_000704.wav    Happy\n",
       "3      ../data/esd/0015/Happy/evaluation/0015_000715.wav    Happy\n",
       "4      ../data/esd/0015/Happy/evaluation/0015_000702.wav    Happy\n",
       "...                                                  ...      ...\n",
       "34995     ../data/esd/0012/Neutral/train/0012_000300.wav  Neutral\n",
       "34996     ../data/esd/0012/Neutral/train/0012_000090.wav  Neutral\n",
       "34997     ../data/esd/0012/Neutral/train/0012_000296.wav  Neutral\n",
       "34998     ../data/esd/0012/Neutral/train/0012_000054.wav  Neutral\n",
       "34999     ../data/esd/0012/Neutral/train/0012_000323.wav  Neutral\n",
       "\n",
       "[35000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_data='../data/esd'\n",
    "imgs_path='../imgs/ood_data_esd/'\n",
    "\n",
    "def load_data(path):\n",
    "    emotion, file_path = [], []\n",
    "    \n",
    "    # iterate over audio files extracting emotion label, file path and speaker info\n",
    "    for root, _, files in os.walk(path):\n",
    "        if len(files): # extract info only if files are found\n",
    "            for filename in files:\n",
    "                if filename.split('.')[1] == 'wav':\n",
    "                    temp_path_split = os.path.dirname(root).split('/')\n",
    "                    emotion.append(temp_path_split[4])\n",
    "                    file_path.append(os.path.join(root, filename))\n",
    "\n",
    "    # prepare dataframe\n",
    "    audio_df = pd.DataFrame(emotion)\n",
    "    audio_df = audio_df.replace({'Happy': 'happiness', 'Neutral': 'neutral', 'Surprise': 'surprise'\n",
    "                                'Sad': 'sadness', 'Angry': 'anger'})\n",
    "    \n",
    "    audio_df = pd.concat([pd.DataFrame(file_path), audio_df], axis=1)\n",
    "    audio_df.columns = ['path', 'emotion']\n",
    "    \n",
    "    return audio_df\n",
    "\n",
    "df = load_data(path_to_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512e078",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d077003",
   "metadata": {},
   "source": [
    "## class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901912f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Happy' 'Surprise' 'Angry' 'Sad' 'Neutral']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# class imbalance plot\n",
    "def class_imbalance_plot():\n",
    "    print(df['emotion'].unique())\n",
    "    plt.figure(figsize = (12,6))\n",
    "    sns.set_theme(style='darkgrid')\n",
    "    sns.countplot(x = 'emotion', data = df)\n",
    "    plt.title('Class distribution')\n",
    "    plt.savefig(imgs_path + 'class_distribution.png')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "class_imbalance_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d8c62",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "- [mfcc extraction info](https://www.researchgate.net/profile/Teddy-Gunawan/publication/353296706_Speech_Emotion_Recognition_Using_Feature_Fusion_of_TEO_and_MFCC_on_Multilingual_Databases/links/613ef96f4e1df2710631ca0a/Speech-Emotion-Recognition-Using-Feature-Fusion-of-TEO-and-MFCC-on-Multilingual-Databases.pdf)\n",
    "- [librosa docs](https://librosa.org/doc/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb93ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import librosa\n",
    "\n",
    "# length of the longest utterance\n",
    "\n",
    "def longest_utterance_length(df):\n",
    "    longest_utterance = 0\n",
    "    for file in df['path']:\n",
    "        wavf, sample_rate = librosa.load(file, res_type='kaiser_fast', sr=44100)\n",
    "        curr_length = librosa.get_duration(y=wavf, sr=sample_rate)\n",
    "        if curr_length > longest_utterance:\n",
    "            longest_utterance = curr_length\n",
    "            \n",
    "    return longest_utterance\n",
    "\n",
    "_duration = longest_utterance_length(df)\n",
    "\n",
    "print(_duration)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d15e283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>686</th>\n",
       "      <th>687</th>\n",
       "      <th>688</th>\n",
       "      <th>689</th>\n",
       "      <th>690</th>\n",
       "      <th>691</th>\n",
       "      <th>692</th>\n",
       "      <th>693</th>\n",
       "      <th>694</th>\n",
       "      <th>695</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-49.180321</td>\n",
       "      <td>-32.914463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>-54.225517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>-35.421291</td>\n",
       "      <td>-32.140652</td>\n",
       "      <td>-31.178898</td>\n",
       "      <td>-30.357868</td>\n",
       "      <td>-32.065575</td>\n",
       "      <td>-32.248047</td>\n",
       "      <td>-32.211929</td>\n",
       "      <td>-32.116116</td>\n",
       "      <td>-32.252506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>-51.581966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>-53.433681</td>\n",
       "      <td>-53.433681</td>\n",
       "      <td>-53.433681</td>\n",
       "      <td>-33.257175</td>\n",
       "      <td>-24.264462</td>\n",
       "      <td>-26.022949</td>\n",
       "      <td>-43.897484</td>\n",
       "      <td>-53.433681</td>\n",
       "      <td>-53.433681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 697 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion          0          1          2          3          4          5  \\\n",
       "0   Happy -49.180321 -49.180321 -49.180321 -49.180321 -49.180321 -49.180321   \n",
       "1   Happy -54.225517 -54.225517 -54.225517 -54.225517 -54.225517 -54.225517   \n",
       "2   Happy -35.421291 -32.140652 -31.178898 -30.357868 -32.065575 -32.248047   \n",
       "3   Happy -51.581966 -51.581966 -51.581966 -51.581966 -51.581966 -51.581966   \n",
       "4   Happy -53.433681 -53.433681 -53.433681 -33.257175 -24.264462 -26.022949   \n",
       "\n",
       "           6          7          8  ...  686  687  688  689  690  691  692  \\\n",
       "0 -49.180321 -49.180321 -32.914463  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1 -54.225517 -54.225517 -54.225517  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -32.211929 -32.116116 -32.252506  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3 -51.581966 -51.581966 -51.581966  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4 -43.897484 -53.433681 -53.433681  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   693  694  695  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 697 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mfcc features\n",
    "def parse_audio_file(path_to_file, _sr, _duration):\n",
    "    # load file\n",
    "    wavf, sample_rate = librosa.load(path_to_file, res_type=\"kaiser_fast\", duration=_duration, sr=_sr)\n",
    "    \n",
    "    # get mfcc features (coefficients = 13, filters = 32)\n",
    "    mfcc = np.array([])\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=wavf, sr=sample_rate, n_mfcc = 13), axis=0)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "mfccVal = []\n",
    "\n",
    "for fpath in df['path']:\n",
    "    mfcc = parse_audio_file(fpath, 44100, 8)\n",
    "    mfccVal.append(mfcc)\n",
    "    \n",
    "# merge emotions with features\n",
    "df = pd.concat([df, pd.DataFrame(mfccVal)], axis=1)\n",
    "    \n",
    "# drop unnecessary column\n",
    "df.drop(columns='path', inplace=True)\n",
    "\n",
    "# fill na's\n",
    "df = df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c3fd6",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201c45c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0          1          2          3          4          5    \\\n",
      "0 -49.180321 -49.180321 -49.180321 -49.180321 -49.180321 -49.180321   \n",
      "1 -54.225517 -54.225517 -54.225517 -54.225517 -54.225517 -54.225517   \n",
      "2 -35.421291 -32.140652 -31.178898 -30.357868 -32.065575 -32.248047   \n",
      "3 -51.581966 -51.581966 -51.581966 -51.581966 -51.581966 -51.581966   \n",
      "4 -53.433681 -53.433681 -53.433681 -33.257175 -24.264462 -26.022949   \n",
      "\n",
      "         6          7          8          9    ...  686  687  688  689  690  \\\n",
      "0 -49.180321 -49.180321 -32.914463 -22.240774  ...  0.0  0.0  0.0  0.0  0.0   \n",
      "1 -54.225517 -54.225517 -54.225517 -54.225517  ...  0.0  0.0  0.0  0.0  0.0   \n",
      "2 -32.211929 -32.116116 -32.252506 -31.230543  ...  0.0  0.0  0.0  0.0  0.0   \n",
      "3 -51.581966 -51.581966 -51.581966 -51.581966  ...  0.0  0.0  0.0  0.0  0.0   \n",
      "4 -43.897484 -53.433681 -53.433681 -53.433681  ...  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   691  692  693  694  695  \n",
      "0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 696 columns]\n",
      "0    happiness\n",
      "1    happiness\n",
      "2    happiness\n",
      "3    happiness\n",
      "4    happiness\n",
      "Name: emotion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def data_split(df):\n",
    "    \n",
    "    # divide data into labels and features\n",
    "    X = df.iloc[:, :].drop(columns=['emotion'])\n",
    "    y = df['emotion']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = data_split(df)\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ece614",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a3c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000,)\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "['anger' 'happiness' 'neutral' 'sadness' 'surprise']\n",
      "(35000, 696, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def data_preprocessing(X, y):\n",
    "\n",
    "    # normalization (z-score, values between -1 and 1)\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    X = (X - mean)/std\n",
    "\n",
    "    # turn data into arrays for keras\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(y.shape)\n",
    "\n",
    "    # label one hot encoding\n",
    "    lb = LabelEncoder()\n",
    "    y = to_categorical(lb.fit_transform(y))\n",
    "\n",
    "    print(y[0:3])\n",
    "\n",
    "    print(lb.classes_)\n",
    "\n",
    "    # data reshaping\n",
    "    X = X[:,:,np.newaxis]\n",
    "\n",
    "    print(X.shape)\n",
    "    \n",
    "    return X, y, lb\n",
    "\n",
    "X, y, lb = data_preprocessing(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4aa195",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4639c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 259, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 259, 1), dtype=tf.float32, name='conv1d_15_input'), name='conv1d_15_input', description=\"created by layer 'conv1d_15_input'\"), but it was called on an input with incompatible shape (None, 696, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 08:51:02.686770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-22 08:51:02.710820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3799900000 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense_20 is incompatible with the layer: expected axis -1 of input shape to have value 256 but received input with shape (None, 1152)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrained_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1629\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1628\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1629\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1631\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/pingwin/miniconda3/envs/DL_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense_20 is incompatible with the layer: expected axis -1 of input shape to have value 256 but received input with shape (None, 1152)\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "predictions = trained_models[0].predict(X)\n",
    "predictions = predictions.argmax(axis=1)\n",
    "predictions = predictions.astype(int).flatten()\n",
    "predictions = (lb.inverse_transform((predictions)))\n",
    "predictions = pd.DataFrame({'Predicted Values': predictions})\n",
    "\n",
    "# actual labels\n",
    "actual = y.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n",
    "actual = (lb.inverse_transform((actual)))\n",
    "actual = pd.DataFrame({'Actual Values': actual})\n",
    "\n",
    "# combine both\n",
    "finaldf = actual.join(predictions)\n",
    "finaldf[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d6084",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# confusion matrix, actual vs predicted\n",
    "cm = confusion_matrix(actual, predictions)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
    "ax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.savefig(imgs_path + 'Initial_Model_Confusion_Matrix.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
